{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/hacidpy310-pub/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/envs/hacidpy310-pub/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validate_default' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'validate_default' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../src\")))\n",
    "\n",
    "from tqdm import tqdm\n",
    "from rag_prompt_template import *\n",
    "from rag_util import *\n",
    "from rag_moduler import *\n",
    "from llm_factory import *\n",
    "from rag_extraction import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise RAG pipeline\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_llm = \"mistralsmall\"\n",
    "# using_llm = \"mistral-ft-multitask\"\n",
    "using_embed = \"hitsnomed\"\n",
    "task = \"entityextraction\"\n",
    "eval_dataset = \"mimicivchunk\"\n",
    "using_extractor = \"None\"\n",
    "using_generator = \"None\"\n",
    "\n",
    "PARAMETERS = {\n",
    "    \"llm_model_name\": LLM[using_llm],\n",
    "    \"tokenizer_name\": LLM[using_llm],\n",
    "    \"embed_model_name\": EMBED_MODEL[using_embed],\n",
    "    \"storage_dir\": f\"../index/snomed_dataset_nodoc_commandr_hitsnomed\", # this is a partial KG indices for testing\n",
    "    # \"storage_dir\": f\"index/snomed_all_dataset_nodoc_hitsnomed\",  # this is a full KG indices for testing\n",
    "    \"input_text_dir\": f\"../data/humandx_data/humandx_findings.json\",\n",
    "    \"context_window\": 32768,\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"case_num\":50,\n",
    "    \"verbose\": True,\n",
    "    \"similarity_top_k\": 30,\n",
    "    \"graph_store_query_depth\": 5,\n",
    "    \"retriever_mode\": \"hybrid\",\n",
    "    \"test_id\": f\"_test_{task}_{eval_dataset}_{using_generator}_extractor_{using_extractor}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/hacidpy310-pub/lib/python3.10/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global embed_model set to: ../llm/embedder/HiT-MiniLM-L12-SnomedCT\n"
     ]
    }
   ],
   "source": [
    "kg_index = init_kg_storage_context(storage_dir=PARAMETERS[\"storage_dir\"], embed_model_name=PARAMETERS[\"embed_model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 9/9 [00:28<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM loaded: ../llm/Mistral-Small-Instruct-2409\n",
      "embed_model loaded: ../llm/embedder/HiT-MiniLM-L12-SnomedCT\n",
      "Settings loaded.\n"
     ]
    }
   ],
   "source": [
    "hf_llm = init_llm_service_context(llm_model_name=PARAMETERS[\"llm_model_name\"], \n",
    "                                    tokenizer_name=PARAMETERS[\"tokenizer_name\"], \n",
    "                                    embed_model_name=PARAMETERS[\"embed_model_name\"],\n",
    "                                    context_window=PARAMETERS[\"context_window\"],\n",
    "                                    max_new_tokens=PARAMETERS[\"max_new_tokens\"],\n",
    "                                    # quantization_config=None,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = build_kg_query_engine(\n",
    "    kg_index,\n",
    "    llm=hf_llm,\n",
    "    retriever_mode=\"hybrid\",\n",
    "    embedding_mode=\"hybrid\",\n",
    "    similarity_top_k=30,\n",
    "    graph_store_query_depth=2,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.99s/it]\n"
     ]
    }
   ],
   "source": [
    "# Swap LLM of the existing KG query engine and rebuild it without re-loading the KG index\n",
    "# !NOT FINISHED YET!\n",
    "\n",
    "# query_engine = swap_llm_and_rebuild_engine(\n",
    "#     kg_index,\n",
    "#     new_llm=\"new_llm_name\",\n",
    "#     retriever_mode=\"hybrid\",\n",
    "#     embedding_mode=\"hybrid\",\n",
    "#     similarity_top_k=30,\n",
    "#     graph_store_query_depth=5,\n",
    "#     verbose=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Question-Answer example\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;32mExtracted keywords: ['type', 'possible', 'Desloratadine', 'concept']\n",
      "\u001b[0m\u001b[1;3;34mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "('2,4,5-trichlorophenoxyacetic acid (substance)', 'type', 'Substance')\n",
      "('Chloramphenicol sodium succinate (substance)', 'type', 'Substance')\n",
      "('Dichlorodiphenyltrichloroethane (substance)', 'type', 'Substance')\n",
      "('Benzquinamide hydrochloride (substance)', 'type', 'Substance')\n",
      "('Melarsomine dihydrochloride (substance)', 'type', 'Substance')\n",
      "('Nitrogen mustard derivative (substance)', 'type', 'Substance')\n",
      "('Trimethoprim hydrochloride (substance)', 'type', 'Substance')\n",
      "('Tropatepine hydrochloride (substance)', 'type', 'Substance')\n",
      "('Lurasidone hydrochloride (substance)', 'type', 'Substance')\n",
      "('Butyrophenone derivative (substance)', 'type', 'Substance')\n",
      "('Fluorothymidine (18-F) (substance)', 'type', 'Substance')\n",
      "('Phenylurea compound (substance)', 'type', 'Substance')\n",
      "('Cinchona alkaloid (substance)', 'type', 'Substance')\n",
      "('Benzylpenicillin (substance)', 'type', 'Substance')\n",
      "('Chlorprothixene (substance)', 'type', 'Substance')\n",
      "('Benzododecinium (substance)', 'type', 'Substance')\n",
      "('Fluorothymidine (substance)', 'type', 'Substance')\n",
      "('Chloramphenicol (substance)', 'type', 'Substance')\n",
      "('Phenylbutazone (substance)', 'type', 'Substance')\n",
      "('Demeclocycline (substance)', 'type', 'Substance')\n",
      "('Chlorothiazide (substance)', 'type', 'Substance')\n",
      "('Chlorpromazine (substance)', 'type', 'Substance')\n",
      "('Carbenoxolone (substance)', 'type', 'Substance')\n",
      "('Phencyclidine (substance)', 'type', 'Substance')\n",
      "('Dicycloverine (substance)', 'type', 'Substance')\n",
      "('Benzquinamide (substance)', 'type', 'Substance')\n",
      "('Chlorambucil (substance)', 'type', 'Substance')\n",
      "('Tetracycline (substance)', 'type', 'Substance')\n",
      "('Phenazocine (substance)', 'type', 'Substance')\n",
      "('Quinidine (substance)', 'type', 'Substance')\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b> Substance</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the most possible type of the concept 'Desloratadine'? Only answer with the type name.\")\n",
    "display(Markdown(f\"<b>{response.response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concept/Entity Extraction example\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>1. Hiatal Hernia (disorder)\n",
       "2. Esophageal ulcer (disorder)\n",
       "3. Back pain (disorder)\n",
       "4. Metastatic lung cancer (disorder)\n",
       "5. CVA (disorder)\n",
       "6. MI (disorder)\n",
       "7. Elective cholecystectomy (procedure)</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "response: 1. Hiatal Hernia (disorder)\n",
      "2. Esophageal ulcer (disorder)\n",
      "3. Back pain (disorder)\n",
      "4. Metastatic lung cancer (disorder)\n",
      "5. CVA (disorder)\n",
      "6. MI (disorder)\n",
      "7. Elective cholecystectomy (procedure)\n"
     ]
    }
   ],
   "source": [
    "# text = \"___ is a ___ man who had severe biliary  pancreatitis resulting in pancreatic necrosis for which he was  treated with nasojejunal feedings and pancreatic rest.  He had  initially had multisystem organ failure, which improved. Mr.  ___ has a large postnecrotic pseudocyst, which has been  drained through a minimally invasive approach into his GI tract.   He has some debris, but this is not currently infected. The  patient was followed by Dr. ___ in his ___  clinic to discuss cholecystectomy. \"\n",
    "\n",
    "text = \"After discussion of all  risks, benefits and possible outcomes, patient was scheduled for  elective cholecystectomy on ___.   Past Medical History: Hiatal Hernia   ___ esophagus   Esophageal ulcer   anxiety   Back pain    Social History: ___ Family History: Mother passed of metastatic lung cancer. Father alive, had CVA  and MI.  No  history of pancreatic malignancy      Physical Exam: Prior Discharge: VS: 98.3, 83, 137/69, 16, 98% RA GEN: NAD, \"\n",
    "\n",
    "entity_extraction_prompt = \"\"\"\\\n",
    "Extract the mentioned SNOMED CT concepts from the given discharge note.\n",
    "\n",
    "Here is the desired types of the concepts: [finding, disorder, procedure, regimen/therapy, morphologic abnormality, body structure, cell structure]\n",
    "\n",
    "Here is the discharge note: {text}.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = query_engine.query(entity_extraction_prompt.format(text=text))\n",
    "display(Markdown(f\"<b>{response}</b>\"))\n",
    "print(\"========================================\")\n",
    "# response = \", \".join(list(dict.fromkeys(response.split(\",\"))))\n",
    "print(f\"response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entity-type Pair Extraction example\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b> Pairs: (Hypertensive patients with psychiatric histories; Disorder), (depression; Disorder), (methyl dopa treated patients with psychiatric histories; Disorder)</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"Antihypertensive drugs and depression: a reappraisal. Eighty-nine new referral hypertensive out-patients and 46 new referral non-hypertensive chronically physically ill out-patients completed a mood rating scale at regular intervals for one year. The results showed a high prevalence of depression in both groups of patients, with no preponderance in the hypertensive group. Hypertensive patients with psychiatric histories had a higher prevalence of depression than the comparison patients. This was accounted for by a significant number of depressions occurring in methyl dopa treated patients with psychiatric histories.\"\n",
    "\n",
    "pair_extraction_prompt = \"\"\"\\\n",
    "Here is the context: {text}.\\\n",
    "\n",
    "Task: Extract the entity-type pairs from the given context with the format of (entity ; type).\\\n",
    "\n",
    "Here is the type list: [Disorder, Substance].\\\n",
    "\n",
    "The steps are as follows:\\\n",
    "1. extract the entity from the given context abstract, using the retrieved sub-graph.\n",
    "2. select ONE most likely type from the list for the extracted entity.\n",
    "3. output the pairs in the format of (entity ; type) strictly.\n",
    "4. repeat the step 1 to step 3.\\\n",
    "\\\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Pairs: (All extracted pairs)\\\n",
    "Answer End:::\\\n",
    "\n",
    "Requirements:\\\n",
    "You MUST provide values for 'Pairs:' in your answer. \\\n",
    "ONLY use the type in the type list: [Disorder, Substance].\\\n",
    "ONLY output valid entity-type pairs without any reasoning.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = query_engine.query(pair_extraction_prompt.format(text=text))\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triple Extraction example\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>1. ('Transoral thyroid surgery (procedure)', 'is modification of', 'Thyroid surgery (procedure)')\n",
       "2. ('Traditional, trans-cervical thyroidectomy (procedure)', 'has definitional manifestation', 'Presence of neck scar (finding)')\n",
       "3. ('Presence of neck scar (finding)', 'associated with', 'Lower quality of life (finding)')\n",
       "4. ('Presence of neck scar (finding)', 'associated with', 'Lower patient satisfaction (finding)')</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"Evaluation of Preference and Utility Measures for Transoral Thyroidectomy. Traditional, trans-cervical thyroidectomy results in the presence of a neck scar, which has been shown to correlate with lower quality of life and lower patient satisfaction. Transoral thyroid surgery (TOTS) has been utilized as an alternative approach to avoid a cutaneous incision and scar by accessing the neck and thyroid through the oral cavity. This study was designed to evaluate patient preference through health-state utility scores for TOTS as compared to conventional trans-cervical thyroidectomy.\"\n",
    "\n",
    "triple_extraction_prompt = f\"\"\"\n",
    "Here is the optional relation list: [temporally follows, after, due to, has realization, associated with, has definitional manifestation, associated finding, associated aetiologic finding, associated etiologic finding, interprets, associated morphology, causative agent, course, finding site, temporally related to, pathological process, direct morphology, is modification of, measures, direct substance, has active ingredient, using, part of].\n",
    "\n",
    "Here is the context: {text}.\n",
    "\n",
    "Extract the SNOMED CT triples from the given context.\n",
    "\n",
    "\"\"\"\n",
    "response = query_engine.query(triple_extraction_prompt)\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medical Diagnostics example\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "Myocarditis due to scarlet fever\n",
       "Acute on chronic combined systolic and diastolic heart failure\n",
       "Tuberculosis of lung, confirmed by culture only\n",
       "Aortic orifice posterior left with respect to pulmonary orifice\n",
       "Acute ST segment elevation myocardial infarction of anterior wall involving right ventricle</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "case_vignette = \"\"\"\n",
    "40 year old female presenting with chest pain\n",
    " Symptom: Worsening chest pain\n",
    " • Onset: 2 weeks ago\n",
    " • Associated with: Cough, dyspnea, fever\n",
    " • Complicated by: Fatigue\n",
    " Social history\n",
    " • Recent construction in Ohio\n",
    " Physical exam\n",
    " • Lungs: Wheezing\n",
    " Diagnostic: X-ray\n",
    " • Interpretation: Normal\n",
    "\"\"\"\n",
    "\n",
    "medical_diagnosis_prompt = \"\"\"\n",
    "Case vignette: {case_vignette}\n",
    "\n",
    "According the given case vignette, provide only the most probable differential diagnosis, no explanation, no recapitulation of the case information or task. \n",
    "Give a maximum of 5 answers, sorted by probability of being the correct diagnosis, most probable first, remove list numbering, \n",
    "and respond with each answer on a new line. Be as concise as possible, no need to be polite.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Diagnosis: (the 5 most probable diagnoses, most probable first)\n",
    "1. \n",
    "2. \n",
    "...\n",
    "Answer End:::\\\n",
    "\n",
    "You MUST provide values for 'Diagnosis' in your answer.\\\n",
    "Do not provide any other information in your response.\\\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = query_engine.query(medical_diagnosis_prompt.format(case_vignette=case_vignette))\n",
    "display(Markdown(f\"<b>{response}</b>\"))\n",
    "# print(f\"Results:\\n{extract_triple(str(response), notebook=True, split_str1='Diagnosis:')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [28:31, 34.22s/it]\n"
     ]
    }
   ],
   "source": [
    "# snomed concepts extraction\n",
    "snomed_extraction_prompt = \"\"\"\\\n",
    "Here is the context: {text}.\\\n",
    "\n",
    "Task: Extract the SNOMED CT triples from the given context with the format of (concept 1 ; relation ; concept 2).\\\n",
    "\n",
    "Here is the optional relation list: [temporally follows, after, due to, has realization, associated with, has definitional manifestation, \n",
    "associated finding, associated aetiologic finding, associated etiologic finding, interprets, associated morphology, causative agent, course, \n",
    "finding site, temporally related to, pathological process, direct morphology, is modification of, measures, direct substance, has active ingredient, using, part of].\\\n",
    "\n",
    "The steps are as follows:\\\n",
    "1. extract the concept 1 and concept 2 from the given context sentence, using the retrieved sub-graph.\n",
    "2. select ONE most likely relation from the list for the extracted concepts.\n",
    "3. output the triplets in the format of (concept 1 ; relation ; concept 2) strictly.\\\n",
    "\\\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Triples: (The extracted triples)\\\n",
    "Answer End:::\\\n",
    "\n",
    "You MUST provide values for 'Triples:' in your answer.\\\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "snomed_description_generation_prompt = \"\"\"\\\n",
    "Here is the context: {text}.\\\n",
    "\n",
    "Here is the optional relation list: [temporally follows, after, due to, has realization, associated with, has definitional manifestation, \n",
    "associated finding, associated aetiologic finding, associated etiologic finding, interprets, associated morphology, causative agent, course, \n",
    "finding site, temporally related to, pathological process, direct morphology, is modification of, measures, direct substance, has active ingredient, using, part of].\\\n",
    "\n",
    "Task: Generate the SNOMED CT descriptions for the given concept.\n",
    "\n",
    "The steps are as follows:\n",
    "1. extract a CONCEPT from the given context sentence, using the retrieved sub-graph.\n",
    "2. generate an EXPRESSION in human-readable phrase that can describe the CONCEPT.\n",
    "3. select one most likely relation from the list between the CONCEPT and the EXPRESSION.\n",
    "4. generate descriptions in the format of (CONCEPT ; relation ; EXPRESSION). Each CONCEPT may have multiple descriptions.\n",
    "5. repeat the step 1 to step 4.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Concept: \n",
    "Descriptions: (The generated descriptions)\n",
    "Answer End:::\\\n",
    "\n",
    "You MUST provide values for 'Concept' and 'Description' in your answer.\\\n",
    "\n",
    "Few-shot examples:\n",
    "Answer:::\n",
    "Concept: apnea\n",
    "Descriptions: (apnea ; interprets ; respiration observable) (apnea ; has interpretation ; absent) (apnea ; finding site ; structure of respiratory system)\n",
    "Answer End:::\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "snomed_extraction_prompt_var_mappings = {\"text\": \"text\"}\n",
    "\n",
    "prompt_tmpl = PromptTemplate(\n",
    "    snomed_description_generation_prompt, template_var_mappings=snomed_extraction_prompt_var_mappings\n",
    ")\n",
    "\n",
    "def query_and_generate_rel(test_id, query_engine, cases=427):\n",
    "    logging.info(f\"Query Engine: {query_engine}\")\n",
    "    with open(\"\") as f:\n",
    "        results = []\n",
    "        sentences = f.readlines()[:cases]\n",
    "        logging.info(f\"Experiment ID: {test_id}\")\n",
    "        print(f\"Number of sentences: {len(sentences)}; Number of cases for test: {cases}\")\n",
    "        for sentence_id, text in tqdm(enumerate(sentences)):\n",
    "            print(f\"Processing sentence {sentence_id} / {len(sentences)}\")\n",
    "            print(f\"Text: {text}\")\n",
    "            retry_count = 0\n",
    "\n",
    "            fmt_prompt = prompt_tmpl.format(\n",
    "                text=text,\n",
    "            )\n",
    "            # print(fmt_prompt)\n",
    "            response = query_engine.query(fmt_prompt)\n",
    "            # display(Markdown(f\"<b>{response}</b>\"))\n",
    "            # results.append(clean_response(str(response)) + \"\\n\")\n",
    "            results.append(extract_triple(str(response), notebook=True) + \"\\n\")\n",
    "            print(f\"Results: {extract_triple(str(response), notebook=True)}\")\n",
    "\n",
    "    with open(f\"results/rel.hyps_{test_id}\", 'w') as f:\n",
    "        f.writelines(results)\n",
    "    \n",
    "    logging.info(f\"Results saved to results/rel.hyps_{test_id}\")\n",
    "    return response\n",
    "\n",
    "logging_setup(log_file=f\"logs/{PARAMETERS['test_id']}.log\", log_level=logging.INFO)\n",
    "\n",
    "response = query_and_generate_rel(test_id = PARAMETERS[\"test_id\"], query_engine = query_engine, cases=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hacidpy310-pub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
